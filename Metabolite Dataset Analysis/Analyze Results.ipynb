{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "data  \u003d pd.read_csv(\u0027results7parsed.csv\u0027)\n\n# sort by best CA\navg_ca \u003d data.sort_values(\u0027Average CA\u0027, ascending\u003dFalse)\navg_rfw \u003d data.sort_values(\u0027RFW CA\u0027, ascending\u003dFalse)\navg_dt \u003d data.sort_values(\u0027DT CA\u0027, ascending\u003dFalse)\n\n# get best 5 average features\nwith open(\u0027CA Features.csv\u0027, \u0027w\u0027)as f :\n    f.write(\u0027Avg\u0027)\n    f.write(avg_ca[:5].to_csv())\n    \n# get best 5 random forest features\nwith open(\u0027CA Features.csv\u0027, \u0027a\u0027)as f :\n    f.write(\u0027Rfw\u0027)\n    f.write(avg_rfw[:5].to_csv())\n    \n# get 5 best decision tree features \nwith open(\u0027CA Features.csv\u0027, \u0027a\u0027)as f :\n    f.write(\u0027Dtree\u0027)\n    f.write(avg_dt[:5].to_csv())\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now, let us take the most interesting features from the csv and write a parser to analyze the feature importances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\u0027\u0027], [\u0027nof_SO3H, nof_PO4, posCharge/Volume, nof_posCharge, molPSA, molLogP\u0027], [\u0027nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\u0027], [\u0027nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\u0027], [\u0027nof_OH, nof_NH2, C_sp3, nof_HBA, PSA/Area, molLogS\u0027], [\u0027nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\u0027], [\u0027nof_OH, nof_NH2, posCharge/Volume, C_R0, nof_HBA, PSA/Area\u0027], [\u0027nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\u0027], [\u0027negCharge/Volume, C_sp3, C_R0, nof_posCharge, nof_HBA, molLogP\u0027], [\u0027nof_acetyl, nof_COOH, nof_PO4, posCharge/Volume, C_R2, molLogP\u0027], [\u0027PSA/Area, nof_Rings, Complexity, nof_SO3H, nof_OH, nof_Chirals, C_R0\u0027], [\u0027\u0027]]\n"
          ]
        }
      ],
      "source": "\ns \u003d\u0027\u0027\u0027nof_SO3H, nof_PO4, posCharge/Volume, nof_posCharge, molPSA, molLogP\nnof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\nnof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\nnof_OH, nof_NH2, C_sp3, nof_HBA, PSA/Area, molLogS\nnof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\nnof_OH, nof_NH2, posCharge/Volume, C_R0, nof_HBA, PSA/Area\nnof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\nnegCharge/Volume, C_sp3, C_R0, nof_posCharge, nof_HBA, molLogP\nnof_acetyl, nof_COOH, nof_PO4, posCharge/Volume, C_R2, molLogP\nPSA/Area, nof_Rings, Complexity, nof_SO3H, nof_OH, nof_Chirals, C_R0\u0027\u0027\u0027\n\n\n\nfeatures \u003d  [[x] for x in s.split(\u0027\\n\u0027)]\nprint(features)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "from graphviz import Source\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Project Settings\n",
        "\n",
        "Specified here are the paths for the data and the features to run over in the list of best features.\n",
        "Each entry in the list is a list containing one single string of the features to try, comma seperated. In this way it is easy to write a script to \n",
        "add entries to try very easily. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "##### set parameters\n",
        "path_train_data \u003d \u0027train.csv\u0027\n",
        "path_test_data \u003d \u0027test.csv\u0027\n",
        "path_all_data \u003d \u0027Dataset Correlated Removed.csv\u0027\n",
        "\n",
        "# set features here\n",
        "\n",
        "best_features \u003d features\n",
        "\n",
        "best_features \u003d [list(map(str.strip, x[0].split(\u0027,\u0027))) for x in best_features]\n",
        "\n",
        "k \u003d len(best_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "This code loads dataset into the variables below and converts the labels to categorical 0, 1 pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "all_data \u003d pd.DataFrame(pd.read_csv(path_all_data))\n",
        "all_labels \u003d all_data[\u0027SLC\u0027].astype(\u0027category\u0027).cat.codes\n",
        "# drop labels\n",
        "all_data.drop(\u0027SLC\u0027, axis\u003d1, inplace\u003dTrue)\n",
        "\n",
        "train_data \u003d pd.DataFrame(pd.read_csv(path_train_data))\n",
        "train_labels \u003d train_data[\u0027SLC\u0027].astype(\u0027category\u0027).cat.codes\n",
        "# drop labels\n",
        "\n",
        "train_data.drop(\u0027SLC\u0027, axis\u003d1, inplace\u003dTrue)\n",
        "\n",
        "test_data \u003d pd.DataFrame(pd.read_csv(path_test_data))\n",
        "test_labels \u003d test_data[\u0027SLC\u0027].astype(\u0027category\u0027).cat.codes\n",
        "# drop labels\n",
        "test_data.drop(\u0027SLC\u0027, axis\u003d1, inplace\u003dTrue)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## AUC and Classification Accuracy - Decision Tree\n",
        "\n",
        "The code below will find the classification accuracy using 10-fold cross-validation using stratified sampling to help class imbalance. The AUC on the test split is also found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape\u003d(124, 0)) while a minimum of 1 is required.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-43-9e145e964ed5\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# find auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdtree\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresort\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 29\u001b[0;31m         \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 799\u001b[0;31m             X_idx_sorted\u003dX_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    583\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--\u003e 585\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!\u003d\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape\u003d(124, 0)) while a minimum of 1 is required."
          ]
        }
      ],
      "source": "# visualize decision tree for input features\n\u0027\u0027\u0027 HYPERPARAMS FOR DECISION TREE\n \n These parameters implement a rudimentary pruning algorithm, would ideally like to use AB pruning\u0027\u0027\u0027\nenable_pruning \u003d True\n# maximum depth of dtree\nmax_depth \u003d 5\n# how many samples your need atleast, at a LEAF node\nmin_samples \u003d 3\n\nd_trees \u003d []\n\n\n# find CA - uses 10-fold cross validation \n# with stratified sampling to help with class imbalance\n# and simple average over subsets\ndt_cas \u003d []\n\n# maintain list of cas over a period\ndt_ca_matrix \u003d []\nNUM_ITER \u003d 50\n\n# run the thing NUM_ITER times\nfor _ in range(NUM_ITER):\n    for i in range(k):\n        aucs \u003d []\n        # make fold\n        skf \u003d StratifiedKFold(n_splits\u003d10, shuffle\u003dTrue)\n        for trx, tex in skf.split(all_data, all_labels):\n            # strip data to required features\n            subset_data \u003d all_data.filter(best_features[i], axis\u003d1)\n            \n            # find auc\n            dtree \u003d DecisionTreeClassifier(presort\u003dTrue, max_depth\u003dmax_depth, min_samples_leaf\u003dmin_samples)\n            dtree.fit(subset_data.iloc[trx, :], all_labels.iloc[trx])        \n            pred \u003d dtree.predict(subset_data.iloc[tex, :])\n            labels \u003d all_labels.iloc[tex]\n            \n            acc \u003d roc_auc_score(labels, pred)\n            # record auc to average later\n            aucs.append(acc)\n        \n        dt_cas.append(np.mean(aucs))\n    dt_ca_matrix.append(dt_cas)\n    dt_cas.clear()\n\n# find AUC \ndt_aucs \u003d []\n\n# run k-fold validation\nfor i in range(k):\n    subset_test_data \u003d test_data.filter(best_features[i], axis\u003d1)\n    subset_train_data \u003d train_data.filter(best_features[i], axis\u003d1)\n    \n    clf \u003d DecisionTreeClassifier(presort\u003dTrue, max_depth\u003dmax_depth, min_samples_leaf\u003dmin_samples)\n    clf.fit(subset_train_data, train_labels)\n    d_trees.append(clf)\n    \n    # make its predictions on test data\n    pred \u003d d_trees[i].predict(subset_test_data)\n    \n    # find auc scores\n    auc \u003d roc_auc_score(test_labels, pred)\n    \n    # record the scores\n    dt_aucs.append(auc)\n\n\nprint(\u0027Decision Tree Results:\u0027)\nprint(\u0027\\tAUC\\tAcc\\tFeatures\u0027)\nfor i, f in enumerate(zip(dt_aucs, dt_cas)):\n    print(\u0027\\t%05.3f\\t%05.3f\\t\u0027 % tuple(f) + \u0027, \u0027.join(best_features[i]))\n\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## AUC and Classification Accuracy - Random Forest Walk\n",
        "\n",
        "The code below will find the classification accuracy using 10-fold cross-validation using stratified sampling to help class imbalance. The AUC on the test split is also found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape\u003d(124, 0)) while a minimum of 1 is required.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-44-fe77f8e37877\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# find auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrfwtree\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 19\u001b[0;31m         \u001b[0mrfwtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mrfwtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 252\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027csc\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    583\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--\u003e 585\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!\u003d\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape\u003d(124, 0)) while a minimum of 1 is required."
          ]
        }
      ],
      "source": "# visualize random forest features\nrfws \u003d []\n\n# find CA - uses 10-fold cross validation \n# with stratified sampling to help with class imbalance\n# and simple average over subsets\nrfw_cas \u003d []\n\n\n# maintain list of cas over a period\nrfw_ca_matrix \u003d []\n\n# run the thing NUM_ITER times\nfor _ in range(NUM_ITER):\n    for i in range(k):\n        aucs \u003d []\n        # make fold\n        skf \u003d StratifiedKFold(n_splits\u003d10, shuffle\u003dTrue)\n        for trx, tex in skf.split(all_data, all_labels):\n            # strip data to required features\n            subset_data \u003d all_data.filter(best_features[i], axis\u003d1)\n            \n            # find auc\n            rfwtree \u003d RandomForestClassifier(n_estimators\u003d100)\n            rfwtree.fit(subset_data.iloc[trx, :], all_labels.iloc[trx])\n            pred \u003d rfwtree.predict(subset_data.iloc[tex, :])\n            labels \u003d all_labels.iloc[tex]\n            \n            acc \u003d roc_auc_score(labels, pred)\n            # record auc to average later\n            aucs.append(acc)\n        \n        rfw_cas.append(np.mean(aucs))\n    \n    rfw_ca_matrix.append(rfw_cas)\n    rfw_cas.clear()\n\n\n# find AUC \nrfw_aucs \u003d []\nfor i in range(k):\n    subset_test_data \u003d test_data.filter(best_features[i], axis\u003d1)\n    subset_train_data \u003d train_data.filter(best_features[i], axis\u003d1)\n    \n    clf \u003d RandomForestClassifier(n_estimators\u003d100)\n    clf.fit(subset_train_data, train_labels)\n    rfws.append(clf)\n    \n    # make its predictions on test data\n    pred \u003d rfws[i].predict(subset_test_data)\n    \n    # find auc scores\n    auc \u003d roc_auc_score(test_labels, pred)\n    \n    # record the scores\n    rfw_aucs.append(auc)\n\nprint(\u0027Random Forest Results:\u0027)\nprint(\u0027\\tAUC\\tAcc\\tFeatures\u0027)\nfor i, f in enumerate(zip(rfw_aucs, rfw_cas)):\n    print(\u0027\\t%05.3f\\t%05.3f\\t\u0027 % tuple(f) + \u0027, \u0027.join(best_features[i]))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Visualizing individual decision trees\n",
        "\n",
        "The tree in variable `dtree` is visualized by the cell below. We can see how it is pruned, the splitting rule, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-45-6b2bcaf25116\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mdtree\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0md_trees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027svg\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "i \u003d 0\n",
        "\n",
        "dtree \u003d d_trees[8]\n",
        "graph \u003d Source(tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "SVG(graph.pipe(format\u003d\u0027svg\u0027))            \n",
        "graph \u003d Source( tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "graph.format \u003d \u0027png\u0027\n",
        "graph.render(\u0027dtree_render\u0027,view\u003dTrue)\n",
        "graph \u003d Source( tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "png_bytes \u003d graph.pipe(format\u003d\u0027png\u0027)\n",
        "with open(\u0027dtree_pipe.png\u0027,\u0027wb\u0027) as f:\n",
        "    f.write(png_bytes)\n",
        "Image(png_bytes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "The feature importances are compared below for decision trees and random forests.\n",
        "Reported below is code to visualize all decision trees. This requires the graphviz package and has some bugs, which will be reported. This code visualizes all decision trees and finds the feature importances for all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "i \u003d 0\n",
        "# visualization\n",
        "for dtree in d_trees:\n",
        "    if i \u003c k:\n",
        "        print(\u0027Feature importances for tree and forest (resp.) %s/%s:\u0027 % (i + 1, k))\n",
        "        for e in zip(dtree.feature_importances_, rfws[i].feature_importances_, best_features[i]):\n",
        "            print(\u0027\\t%6f\\t%6f\\t%s\u0027 % e)\n",
        "        \n",
        "        try:\n",
        "            graph \u003d Source(tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "            SVG(graph.pipe(format\u003d\u0027svg\u0027))            \n",
        "            graph \u003d Source( tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "            graph.format \u003d \u0027png\u0027\n",
        "            graph.render(\u0027dtree_render\u0027,view\u003dTrue)\n",
        "            graph \u003d Source( tree.export_graphviz(dtree, out_file\u003dNone, feature_names\u003dbest_features[i][:dtree.n_features_]))\n",
        "            png_bytes \u003d graph.pipe(format\u003d\u0027png\u0027)\n",
        "            with open(\u0027dtree_pipe.png\u0027,\u0027wb\u0027) as f:\n",
        "                f.write(png_bytes)\n",
        "            Image(png_bytes)\n",
        "        except:\n",
        "            print(\u0027Something went wrong with rendering graph\u0027)\n",
        "    else:\n",
        "        print(\u0027Warning, code may be buggy\u0027)\n",
        "    i +\u003d 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}