{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('results7parsed.csv')\n",
    "\n",
    "# sort by best CA\n",
    "avg_ca = data.sort_values('Average CA', ascending=False)\n",
    "avg_rfw = data.sort_values('RFW CA', ascending=False)\n",
    "avg_dt = data.sort_values('DT CA', ascending=False)\n",
    "\n",
    "with open('CA Features.csv', 'w')as f :\n",
    "    f.write('Avg')\n",
    "    f.write(avg_ca[:5].to_csv())\n",
    "    \n",
    "\n",
    "with open('CA Features.csv', 'a')as f :\n",
    "    f.write('Rfw')\n",
    "    f.write(avg_rfw[:5].to_csv())\n",
    "    \n",
    "    \n",
    "with open('CA Features.csv', 'a')as f :\n",
    "    f.write('Dtree')\n",
    "    f.write(avg_dt[:5].to_csv())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let us take the most interesting features from the csv and write a parser to analyze the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[''], ['nof_SO3H, nof_PO4, posCharge/Volume, nof_posCharge, molPSA, molLogP'], ['nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area'], ['nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS'], ['nof_OH, nof_NH2, C_sp3, nof_HBA, PSA/Area, molLogS'], ['nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS'], ['nof_OH, nof_NH2, posCharge/Volume, C_R0, nof_HBA, PSA/Area'], ['nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area'], ['negCharge/Volume, C_sp3, C_R0, nof_posCharge, nof_HBA, molLogP'], ['nof_acetyl, nof_COOH, nof_PO4, posCharge/Volume, C_R2, molLogP'], ['PSA/Area, nof_Rings, Complexity, nof_SO3H, nof_OH, nof_Chirals, C_R0'], ['']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s ='''\n",
    "nof_SO3H, nof_PO4, posCharge/Volume, nof_posCharge, molPSA, molLogP\n",
    "nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\n",
    "nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\n",
    "nof_OH, nof_NH2, C_sp3, nof_HBA, PSA/Area, molLogS\n",
    "nof_OH, nof_NH2, negCharge/Volume, C_sp3, PSA/Area, molLogS\n",
    "nof_OH, nof_NH2, posCharge/Volume, C_R0, nof_HBA, PSA/Area\n",
    "nof_OH, nof_NH2, nof_PO4, C_R0, nof_HBA, PSA/Area\n",
    "negCharge/Volume, C_sp3, C_R0, nof_posCharge, nof_HBA, molLogP\n",
    "nof_acetyl, nof_COOH, nof_PO4, posCharge/Volume, C_R2, molLogP\n",
    "PSA/Area, nof_Rings, Complexity, nof_SO3H, nof_OH, nof_Chirals, C_R0\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "features =  [[x] for x in s.split('\\n')]\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from graphviz import Source\n",
    "from sklearn import tree\n",
    "from IPython.display import SVG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Project Settings\n",
    "\n",
    "Specified here are the paths for the data and the features to run over in the list of best features.\n",
    "Each entry in the list is a list containing one single string of the features to try, comma seperated. In this way it is easy to write a script to \n",
    "add entries to try very easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "##### set parameters\n",
    "path_train_data = 'train.csv'\n",
    "path_test_data = 'test.csv'\n",
    "path_all_data = 'Dataset Correlated Removed.csv'\n",
    "\n",
    "# set features here\n",
    "\n",
    "best_features = features\n",
    "\n",
    "best_features = [list(map(str.strip, x[0].split(','))) for x in best_features]\n",
    "\n",
    "k = len(best_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "This code loads dataset into the variables below and converts the labels to categorical 0, 1 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "all_data = pd.DataFrame(pd.read_csv(path_all_data))\n",
    "all_labels = all_data['SLC'].astype('category').cat.codes\n",
    "# drop labels\n",
    "all_data.drop('SLC', axis=1, inplace=True)\n",
    "\n",
    "train_data = pd.DataFrame(pd.read_csv(path_train_data))\n",
    "train_labels = train_data['SLC'].astype('category').cat.codes\n",
    "# drop labels\n",
    "\n",
    "train_data.drop('SLC', axis=1, inplace=True)\n",
    "\n",
    "test_data = pd.DataFrame(pd.read_csv(path_test_data))\n",
    "test_labels = test_data['SLC'].astype('category').cat.codes\n",
    "# drop labels\n",
    "test_data.drop('SLC', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## AUC and Classification Accuracy - Decision Tree\n",
    "\n",
    "The code below will find the classification accuracy using 10-fold cross-validation using stratified sampling to help class imbalance. The AUC on the test split is also found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(124, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-9e145e964ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# find auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    583\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 585\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(124, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# visualize decision tree for input features\n",
    "''' HYPERPARAMS FOR DECISION TREE\n",
    " \n",
    " These parameters implement a rudimentary pruning algorithm, would ideally like to use AB pruning'''\n",
    "enable_pruning = True\n",
    "# maximum depth of dtree\n",
    "max_depth = 5\n",
    "# how many samples your need atleast, at a LEAF node\n",
    "min_samples = 3\n",
    "\n",
    "d_trees = []\n",
    "\n",
    "\n",
    "# find CA - uses 10-fold cross validation \n",
    "# with stratified sampling to help with class imbalance\n",
    "# and simple average over subsets\n",
    "dt_cas = []\n",
    "\n",
    "for i in range(k):\n",
    "    aucs = []\n",
    "    # make fold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for trx, tex in skf.split(all_data, all_labels):\n",
    "        # strip data to required features\n",
    "        subset_data = all_data.filter(best_features[i], axis=1)\n",
    "        \n",
    "        # find auc\n",
    "        dtree = DecisionTreeClassifier(presort=True, max_depth=max_depth, min_samples_leaf=min_samples)\n",
    "        dtree.fit(subset_data.iloc[trx, :], all_labels.iloc[trx])        \n",
    "        pred = dtree.predict(subset_data.iloc[tex, :])\n",
    "        labels = all_labels.iloc[tex]\n",
    "        \n",
    "        acc = roc_auc_score(labels, pred)\n",
    "        # record auc to average later\n",
    "        aucs.append(acc)\n",
    "    \n",
    "    dt_cas.append(np.mean(aucs))\n",
    "    \n",
    "\n",
    "# find AUC \n",
    "dt_aucs = []\n",
    "for i in range(k):\n",
    "    subset_test_data = test_data.filter(best_features[i], axis=1)\n",
    "    subset_train_data = train_data.filter(best_features[i], axis=1)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(presort=True, max_depth=max_depth, min_samples_leaf=min_samples)\n",
    "    clf.fit(subset_train_data, train_labels)\n",
    "    d_trees.append(clf)\n",
    "    \n",
    "    # make its predictions on test data\n",
    "    pred = d_trees[i].predict(subset_test_data)\n",
    "    \n",
    "    # find auc scores\n",
    "    auc = roc_auc_score(test_labels, pred)\n",
    "    \n",
    "    # record the scores\n",
    "    dt_aucs.append(auc)\n",
    "    \n",
    "print('Decision Tree Results:')\n",
    "print('\\tAUC\\tAcc\\tFeatures')\n",
    "for i, f in enumerate(zip(dt_aucs, dt_cas)):\n",
    "    print('\\t%05.3f\\t%05.3f\\t' % tuple(f) + ', '.join(best_features[i]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## AUC and Classification Accuracy - Random Forest Walk\n",
    "\n",
    "The code below will find the classification accuracy using 10-fold cross-validation using stratified sampling to help class imbalance. The AUC on the test split is also found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(124, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fe77f8e37877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# find auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrfwtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mrfwtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfwtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kaustubh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    583\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 585\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(124, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# visualize random forest features\n",
    "rfws = []\n",
    "\n",
    "# find CA - uses 10-fold cross validation \n",
    "# with stratified sampling to help with class imbalance\n",
    "# and simple average over subsets\n",
    "rfw_cas = []\n",
    "\n",
    "for i in range(k):\n",
    "    aucs = []\n",
    "    # make fold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for trx, tex in skf.split(all_data, all_labels):\n",
    "        # strip data to required features\n",
    "        subset_data = all_data.filter(best_features[i], axis=1)\n",
    "        \n",
    "        # find auc\n",
    "        rfwtree = RandomForestClassifier(n_estimators=100)\n",
    "        rfwtree.fit(subset_data.iloc[trx, :], all_labels.iloc[trx])\n",
    "        pred = rfwtree.predict(subset_data.iloc[tex, :])\n",
    "        labels = all_labels.iloc[tex]\n",
    "        \n",
    "        acc = roc_auc_score(labels, pred)\n",
    "        # record auc to average later\n",
    "        aucs.append(acc)\n",
    "    \n",
    "    rfw_cas.append(np.mean(aucs))\n",
    "    \n",
    "\n",
    "# find AUC \n",
    "rfw_aucs = []\n",
    "for i in range(k):\n",
    "    subset_test_data = test_data.filter(best_features[i], axis=1)\n",
    "    subset_train_data = train_data.filter(best_features[i], axis=1)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(subset_train_data, train_labels)\n",
    "    rfws.append(clf)\n",
    "    \n",
    "    # make its predictions on test data\n",
    "    pred = rfws[i].predict(subset_test_data)\n",
    "    \n",
    "    # find auc scores\n",
    "    auc = roc_auc_score(test_labels, pred)\n",
    "    \n",
    "    # record the scores\n",
    "    rfw_aucs.append(auc)\n",
    "\n",
    "print('Random Forest Results:')\n",
    "print('\\tAUC\\tAcc\\tFeatures')\n",
    "for i, f in enumerate(zip(rfw_aucs, rfw_cas)):\n",
    "    print('\\t%05.3f\\t%05.3f\\t' % tuple(f) + ', '.join(best_features[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Visualizing individual decision trees\n",
    "\n",
    "The tree in variable `dtree` is visualized by the cell below. We can see how it is pruned, the splitting rule, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6b2bcaf25116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_trees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "dtree = d_trees[8]\n",
    "graph = Source(tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "SVG(graph.pipe(format='svg'))            \n",
    "graph = Source( tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "graph.format = 'png'\n",
    "graph.render('dtree_render',view=True)\n",
    "graph = Source( tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "png_bytes = graph.pipe(format='png')\n",
    "with open('dtree_pipe.png','wb') as f:\n",
    "    f.write(png_bytes)\n",
    "Image(png_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Feature importance\n",
    "\n",
    "The feature importances are compared below for decision trees and random forests.\n",
    "Reported below is code to visualize all decision trees. This requires the graphviz package and has some bugs, which will be reported. This code visualizes all decision trees and finds the feature importances for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "# visualization\n",
    "for dtree in d_trees:\n",
    "    if i < k:\n",
    "        print('Feature importances for tree and forest (resp.) %s/%s:' % (i + 1, k))\n",
    "        for e in zip(dtree.feature_importances_, rfws[i].feature_importances_, best_features[i]):\n",
    "            print('\\t%6f\\t%6f\\t%s' % e)\n",
    "        \n",
    "        try:\n",
    "            graph = Source(tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "            SVG(graph.pipe(format='svg'))            \n",
    "            graph = Source( tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "            graph.format = 'png'\n",
    "            graph.render('dtree_render',view=True)\n",
    "            graph = Source( tree.export_graphviz(dtree, out_file=None, feature_names=best_features[i][:dtree.n_features_]))\n",
    "            png_bytes = graph.pipe(format='png')\n",
    "            with open('dtree_pipe.png','wb') as f:\n",
    "                f.write(png_bytes)\n",
    "            Image(png_bytes)\n",
    "        except:\n",
    "            print('Something went wrong with rendering graph')\n",
    "    else:\n",
    "        print('Warning, code may be buggy')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
